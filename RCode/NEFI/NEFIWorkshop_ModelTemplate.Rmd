State-space model - revised by S. LaDeau (11/2017) from the EcoForecast Activity by Michael Dietze, with reference "Ecological Forecasting", chapter 8
========================================================

The data used for this example are from summer weekly(ish) Gloetrichia echinulata (Gloeo.) sampling at 4 locations in Lake Sunapee, NH. The data are provided by Kathryn Cottingham, and should not be used without permission outside this workshop.

This activity will explore the state-space framework for modeling time-series and spatial data sets. It is based on separating the process model, which describes how the system evolves in time or space, from the observation (data) model. The state-space model gets its name because the model estimates that true value of the underlying **latent** state variables.



```{r}
install.packages("tidyverse")
library(readxl)
library(rjags)
library(runjags)
library(moments)
library(geosphere)
```

#Reading in and visualize data

```{r}

Data=read.csv("~/GitHub/GLEON_Bayesian_WG/Datasets/Sunapee/SummarizedData/All_Sites_Gloeo_light_wtrtemp.csv")
Data$date=format(as.Date(Data$date), "%Y-%m-%d")
Data$daylength=daylength(43.3802, Data$date)
DL = Data$daylength
Temp= Data$watertemp_mean

#Subset by Site
Midge=subset(Data, site=="Midge")
Coffin=subset(Data, site=="Coffin")
Fichter=subset(Data, site=="Fichter")
Newbury=subset(Data, site=="Newbury")

#Choose correct site
dat=Midge
#dat=Coffin
#dat=Fichter
#dat=Newbury

time=as.character(dat$date)
#times<-as.Date(time)

##look at response variable 
y<-round(dat$totalperL*141.3707) #converting colonies per Liter to count data: volume of 2, ~1 m net tows
hist(y)  
N=length(y)
range(y)

```

Next define the JAGS code. The code itself has three components, the data model, the process model, and the priors. The data model relates the observed data, y, at any time point to the latent variable, x. For this example we'll assume that the observation model just consists of Gaussian observation error. The process model relates the state of the system at one point in time to the state one time step ahead. In this case we'll start with the simplest possible process model, a random walk, which just consists of Gaussian process error centered around the current value of the system. Finally, we need to define priors for all stochastic variables, including the initial value of x, the process error, and the observation error.

##Random Walk Model

```{r}
RandomWalk = "

  #### Data Model
  model{
  for(i in 1:N){
    #this fits the blended model to your observed data. 
    y[i] ~ dpois(m[i])
    
   
    #when comparing these values to the data, we need to exponentiate
    m[i] <- exp(mu[i]) 
  }

   #### Process Model
  for(i in 2:N){
    mu[i]~dnorm(mu[i-1],tau_add) #mu's here are on log scale
  }
  
  #### Priors
  mu[1] ~ dnorm(x_ic,tau_ic) 
  tau_add ~ dgamma(a_add,r_add)
  theta~ dbeta(alpha, epsilon)
}
"
```

##Random Walk Zero-Inflation Model

```{r}
RandomWalkZIP = "

  #### Data Model
  model{
  for(i in 1:N){
    #this fits the blended model to your observed data. 
    y[i] ~ dpois(m[i])
    
    #This blends the poisson and zero inflation models
    m[i] <- exp(mu[i])*b[i] + 1E-10 #only when comparing them to the data, we need to exponentiate
    
    #this is the bernoulli outcome of the zero inflation
    b[i] ~ dbern(theta)
  }

   #### Process Model
  for(i in 2:N){
    mu[i]~dnorm(mu[i-1],tau_add) #mu's here are on log scale
  }
  
  #### Priors
  mu[1] ~ dnorm(x_ic,tau_ic) 
  tau_add ~ dgamma(a_add,r_add)
  theta~ dbeta(alpha, epsilon)
}
"
```

##Model including Day Length (Linear)

```{r}

DayLength = "

  #### Data Model
  model{
  for(i in 1:N){
    #this fits the blended model to your observed data. 
    y[i] ~ dpois(m[i])
    
    #This blends the poisson and zero inflation models
    m[i] <- exp(mu[i])
  }

   #### Process Model
  for(i in 2:N){
    mu[i]~dnorm(lambda[i],tau_add) #mu's here are on log scale
    lambda[i] <- beta[1] + beta[2]*mu[i-1] + beta[3]*DL[i]

  }
  
  #### Priors
  mu[1] ~ dnorm(x_ic,tau_ic) 
  tau_add ~ dgamma(a_add,r_add)
  #theta~ dbeta(alpha, epsilon)
  beta ~ dmnorm(beta.m,beta.v)

}
"
```

##Model including DayLength: Quadratic 

```{r}

DayLength_Quad = "

  #### Data Model
  model{
  for(i in 1:N){
    #this fits the blended model to your observed data. 
    y[i] ~ dpois(m[i])
    
    m[i] <- exp(mu[i])

  }

   #### Process Model
  for(i in 2:N){
    mu[i]~dnorm(lambda[i],tau_add) #mu's here are on log scale
    lambda[i] <- beta[1] + beta[2]*mu[i-1] + beta[3]*DL[i] + beta[4]*DL[i]^2

  }
  
  #### Priors
  mu[1] ~ dnorm(x_ic,tau_ic) 
  tau_add ~ dgamma(a_add,r_add)
  #theta~ dbeta(alpha, epsilon)
  beta ~ dmnorm(beta.m,beta.v)

}
"
```

##Model including Water Temp (Exponential)

```{r}

TempExp = "

  #### Data Model
  model{
  for(i in 1:N){
    #this fits the blended model to your observed data. 
    y[i] ~ dpois(m[i])
    
    m[i] <- exp(mu[i])
    
  }

   #### Process Model
  for(i in 2:N){
    mu[i]~dnorm(lambda[i],tau_add) #mu's here are on log scale
    lambda[i] <- beta[1] + beta[2]*mu[i-1] + beta[3]*exp(Temp[i])

  }
  
  #### Priors
  mu[1] ~ dnorm(x_ic,tau_ic) 
  tau_add ~ dgamma(a_add,r_add)
  #theta~ dbeta(alpha, epsilon)
  beta ~ dmnorm(beta.m,beta.v)

}
"
```

##Model including Water Temp: Quadratic 

```{r}

Temp_Quad = "

  #### Data Model
  model{
  for(i in 1:N){
    #this fits the blended model to your observed data. 
    y[i] ~ dpois(m[i])
    
    m[i] <- exp(mu[i])
  
  }

   #### Process Model
  for(i in 2:N){
    mu[i]~dnorm(lambda[i],tau_add) #mu's here are on log scale
    lambda[i] <- beta[1] + beta[2]*mu[i-1] + beta[3]*Temp[i] + beta[4]*Temp[i]^2

  }
  
  #### Priors
  mu[1] ~ dnorm(x_ic,tau_ic) 
  tau_add ~ dgamma(a_add,r_add)
  #theta~ dbeta(alpha, epsilon)
  beta ~ dmnorm(beta.m,beta.v)

}
"
```

##Model including Logistic Growth 

```{r}

Logistic = "

  #### Data Model
  model{
  for(i in 1:N){
    #this fits the blended model to your observed data. 
    y[i] ~ dpois(m[i])
    
    m[i] <- exp(mu[i])
  
  }

   #### Process Model
  for(i in 2:N){
    mu[i]~dnorm(lambda[i],tau_add) 
    lambda[i] <- log(beta[1]*m[i-1]+ beta[2]*m[i-1]^2)

  }
  
  #### Priors
  mu[1] ~ dnorm(x_ic,tau_ic) 
  tau_add ~ dgamma(a_add,r_add)
  #theta~ dbeta(alpha, epsilon)
  beta~ dmnorm(beta.m, beta.v)

}
"
```

#Betas: Change before running model

```{r}
beta.m <- as.vector(c(0,0,0)) ##CHANGE THE NUMBER OF BETAS TO MATCH YOUR MODEL
beta.v <- solve(diag(1E-03,3)) ##CHANGE THE NUMBER OF BETAS TO MATCH YOUR MODEL
```


#JAGS Plug-Ins

```{r}

#JAGS Plug-ins: Add each separate model here 

data.RandomWalk <- list(y=y, N=length(y),x_ic=log(0.1),tau_ic=100,a_add=.001,r_add=.001)
variable.names.RandomWalk<- c("tau_add")
variable.namesout.RandomWalk<- c("tau_add", "mu")

data.RandomWalkZIP <- list(y=y, N=length(y),x_ic=log(0.1),tau_ic=100,a_add=.001,r_add=.001)
variable.names.RandomWalkZIP<- c("tau_add")
variable.namesout.RandomWalkZIP<- c("tau_add", "mu")

data.DayLength <- list(y=y, beta.m=beta.m, beta.v=beta.v, DL=DL, N=length(y),x_ic=log(0.1),tau_ic=100,a_add=.001,r_add=.001)
variable.names.DayLength <- c("tau_add", "beta")
variable.namesout.DayLength <- c("tau_add", "beta", "mu")

data.DayLength_Quad <- list(y=y, beta.m=beta.m, beta.v=beta.v, DL=DL, N=length(y),x_ic=log(0.1),tau_ic=100,a_add=.001,r_add=.001)
variable.names.DayLength <- c("tau_add", "beta")
variable.namesout.DayLength <- c("tau_add", "beta", "mu")

data.TempExp <- list(y=y, beta.m=beta.m, beta.v=beta.v, Temp=Temp, N=length(y),x_ic=log(0.1),tau_ic=100,a_add=.001,r_add=.001)
variable.names.TempExp <- c("tau_add", "beta")
variable.namesout.TempExp <- c("tau_add", "beta", "mu")

data.Temp_Quad <- list(y=y, beta.m=beta.m, beta.v=beta.v, Temp=Temp, N=length(y),x_ic=log(0.1),tau_ic=100,a_add=.001,r_add=.001)
variable.names.Temp_Quad <- c("tau_add", "beta")
variable.namesout.Temp_Quad <- c("tau_add", "beta", "mu")

data.Logistic <- list(y=y, beta.m=beta.m, beta.v=beta.v, N=length(y),x_ic=log(0.1),tau_ic=100,a_add=.001,r_add=.001)
variable.names.Logistic <- c("tau_add", "beta")
variable.namesout.Logistic <- c("tau_add", "beta", "mu")
```

Next we need to define the initial state of the model's parameters for each chain in the MCMC. The overall initialization is stored as a list the same length as the number of chains, where each chain is passed a list of the initial values for each parameter. Unlike the definition of the priors, which had to be done independent of the data, the inidialization of the MCMC is allowed (and even encouraged) to use the data. However, each chain should be started from different initial conditions. We handle this below by basing the initial conditions for each chain off of a different random sample of the original data. 

```{r}
nchain = 3
init <- list()
for(i in 1:nchain){
  y.samp = sample(y,length(y),replace=TRUE)
  init[[i]] <- list(tau_add=1/var(diff(y.samp)))
}
```

#Edit These Before Running a Model 

```{r}

name="RandomWalk.R"
model=paste0("~/GitHub/GLEON_Bayesian_WG/RCode/NEFI/Jags_Models/",name) ##TYPE IN WHICH MODEL YOU WANT TO RUN
data.model=data.RandomWalk ##TYPE IN WHICH MODEL YOU WANT TO RUN
variable.names.model=variable.names.RandomWalk ##TYPE IN WHICH MODEL YOU WANT TO RUN
variable.namesout.model=variable.namesout.RandomWalk ##TYPE IN WHICH MODEL YOU WANT TO RUN

```

Now that we've defined the model, the data, and the initialization, we need to send all this info to JAGS, which will return the JAGS model object.

```{r}

j.model   <- jags.model (file = "~/GitHub/GLEON_Bayesian_WG/RCode/NEFI/Jags_Models/RandomWalk.R", 
                             data = data.model, 
                             inits = init,
                             n.chains = 3)
```

Next, given the defined JAGS model, we'll want to take a few samples from the MCMC chain and assess when the model has converged. To take samples from the MCMC object we'll need to tell JAGS what variables to track and how many samples to take.

Since rjags returns the samples as a CODA object, we can use any of the diagnositics in the R *coda* library to test for convergence, summarize the output, or visualize the chains.

```{r}

jags.out <- run.jags(model = j.model,
                       data = data.model,
                       adapt =  1000,
                       burnin =  500,
                       sample = 2500,
                       n.chains = 3,
                       inits=init,
                       monitor = variable.namesout.model)

write.jagsfile(jags.out, file=paste0("~/GitHub/GLEON_Bayesian_WG/RCode/NEFI/Jags_Models/",name), 
              remove.tags = TRUE, write.data = TRUE, write.inits = TRUE)

plot(jags.out, vars=variable.names.model)

DIC=dic.samples(j.model, n.iter=5000)
DIC

```

Given the full joint posterior samples, we're next going to visualize the output by just looking at the 95% credible interval of the timeseries of X's and compare that to the observed Y's. To do so we'll convert the coda output into a matrix and then calculate the quantiles. Looking at colnames(out) will show you that the first two columns are `tau_add` and `tau_obs`, so we calculate the CI starting from the 3rd column. We also transform the samples back from the log domain to the linear domain.

```{r}

out <- as.matrix(jags.out)
mus=grep("mu", colnames(out))
mu = exp(out[,mus])

times=c(1:length(mus))
time.rng = c(1,length(times)) ## adjust to zoom in and out
ciEnvelope <- function(x,ylo,yhi,...){
  polygon(cbind(c(x, rev(x), x[1]), c(ylo, rev(yhi),
                                      ylo[1])), border = NA,...) 
}
ci <- apply(exp(out[,mus]),2,quantile,c(0.025,0.5,0.975))

plot(times,ci[2,],type='n',ylim=range(y+.01,na.rm=TRUE), log="y", ylab="colonies",xlim=times[time.rng])

ciEnvelope(times,ci[1,],ci[3,],col="lightBlue")
points(times,y,pch="+",cex=0.5)
```

one step ahead prediction: can plot using code above; plot out-of-sample predictions first because wide CIs; calculate means and plot predicted vs. observed
```{r}

nsamp = 500
out <- as.matrix(jags.out)
samp <- sample.int(nrow(out),nsamp)

## sample initial conditions
mus=grep("mu", colnames(out))
mu = out[samp,mus] 
times=c(1:length(mus))

## sample tau
tau = out[samp,grep("tau",colnames(out))]

pred <- matrix(NA, nrow=nsamp,ncol=ncol(mu))
TS1 <- NULL

for (t in 2:ncol(mu)){
pred[,t] = rnorm(nsamp,mu[,t-1],tau) #exponentiate these before comparing to data, because mu on log scale
}

#Visualization

time.rng = c(1,length(times)) ## adjust to zoom in and out
ciEnvelope <- function(x,ylo,yhi,...){
  polygon(cbind(c(x, rev(x), x[1]), c(ylo, rev(yhi),
                                      ylo[1])), border = NA,...) 
}
out <- as.matrix(jags.out)
mus=grep("mu", colnames(out))
mu = exp(out[,mus])
ci <- apply(exp(out[,mus]),2,quantile,c(0.025,0.5,0.975))
pi <- apply(exp(pred),2,quantile,c(0.025,0.5,0.975), na.rm=TRUE)

plot(times,ci[2,],type='n',ylim=range(y+.01,na.rm=TRUE), log="y", ylab="colonies/L",xlim=times[time.rng])
ciEnvelope(times,pi[1,],pi[3,],col="Green")
ciEnvelope(times,ci[1,],ci[3,],col="lightBlue")
points(times,y,pch="+",cex=0.5)

```

#Checks

```{r}

#mu vs. preds

diffs <- matrix(NA,nrow=nsamp,ncol=ncol(mu))

for(i in 1:nsamp){
  for(j in 1:ncol(mu)){
diffs[i,j]=mu[i,j]-pred[i,j]
  }
}
row_sums=rowSums(diffs, na.rm=TRUE) #NA.rm required because first column is NA
pred_sum=sum(row_sums)

#y vs. preds

obs_diff= vector(mode="numeric", length=0)

for(i in 1:ncol(pred)){
  obs_diff[i]=mean(pred[,i])-y[i]
}

obspred_sum=sum(obs_diff, na.rm=TRUE)
obspred_sum

```

